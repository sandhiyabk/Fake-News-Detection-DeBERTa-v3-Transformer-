{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf81e5fb9a76441886f26f15e7ecaa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2bf9b90ccae944918465312b5c0a6207",
              "IPY_MODEL_95e1fb7a52d14ab59a92bf3624954111",
              "IPY_MODEL_3dabf5b1b7574043b33ca4fbee409762"
            ],
            "layout": "IPY_MODEL_e36663f8ffc6423097d6914d9a8eadf0"
          }
        },
        "2bf9b90ccae944918465312b5c0a6207": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99d7199e1b5344348f52b3cea1b0db02",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_83a915a450d24571af3b05ead4352215",
            "value": "Castingâ€‡theâ€‡dataset:â€‡100%"
          }
        },
        "95e1fb7a52d14ab59a92bf3624954111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9386a77c078043b18158da9ff6cbc73b",
            "max": 1522,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_556646963e384c82a548a2f018292e5f",
            "value": 1522
          }
        },
        "3dabf5b1b7574043b33ca4fbee409762": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b08f725a26154cb9b580587caba4d64d",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_137c5f83d6af450ba9edae9824313caa",
            "value": "â€‡1522/1522â€‡[00:00&lt;00:00,â€‡35184.09â€‡examples/s]"
          }
        },
        "e36663f8ffc6423097d6914d9a8eadf0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99d7199e1b5344348f52b3cea1b0db02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83a915a450d24571af3b05ead4352215": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9386a77c078043b18158da9ff6cbc73b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556646963e384c82a548a2f018292e5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b08f725a26154cb9b580587caba4d64d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "137c5f83d6af450ba9edae9824313caa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-eGnJ8XItdfQ",
        "outputId": "b7d8b9af-0a40-45cb-af29-7e2bb8df3e66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All libraries installed âœ…\n"
          ]
        }
      ],
      "source": [
        "!pip install -q \"transformers>=4.41\" datasets accelerate evaluate scikit-learn pandas sentencepiece\n",
        "!pip install -q --upgrade \"transformers>=4.41\" accelerate datasets evaluate\n",
        "!pip install -q gradio wikipedia vaderSentiment requests\n",
        "\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"All libraries installed âœ…\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oWYdNwaFtxrV",
        "outputId": "a9742480-5b63-47c4-a330-c7d00fa637dd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from datasets import Dataset, ClassLabel, Value\n",
        "\n",
        "FAKE_PATH = '/content/drive/MyDrive/NewsFakeCOVID-19_5.csv'\n",
        "REAL_PATH = '/content/drive/MyDrive/NewsRealCOVID-19_5.csv'\n",
        "\n",
        "fake_df = pd.read_csv(FAKE_PATH).copy()\n",
        "real_df = pd.read_csv(REAL_PATH).copy()\n",
        "\n",
        "fake_df['label'] = 0  # 0 = Fake\n",
        "real_df['label'] = 1  # 1 = Real\n",
        "\n",
        "df = pd.concat([fake_df, real_df], ignore_index=True)\n",
        "# Your files had 'content' as the text column:\n",
        "if 'text' not in df.columns and 'content' in df.columns:\n",
        "    df = df.rename(columns={'content': 'text'})\n",
        "# Basic cleanups\n",
        "df.dropna(subset=['text', 'label'], inplace=True)\n",
        "df = df.sample(frac=1.0, random_state=42).reset_index(drop=True)  # shuffle\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"Counts -> Fake(0):\", (df['label']==0).sum(), \"Real(1):\", (df['label']==1).sum())\n",
        "print(\"Total rows:\", len(df))\n",
        "# Hugging Face Dataset + split\n",
        "dataset = Dataset.from_pandas(df[['text','label']])\n",
        "# Cast the 'label' column to ClassLabel for stratification\n",
        "features = dataset.features.copy()\n",
        "features['label'] = ClassLabel(num_classes=2, names=['Fake', 'Real'])\n",
        "dataset = dataset.cast(features)\n",
        "train_test = dataset.train_test_split(test_size=0.2, seed=42, stratify_by_column='label')\n",
        "train_ds, eval_ds = train_test['train'], train_test['test']\n",
        "print(f\"Train: {len(train_ds)}  |  Eval: {len(eval_ds)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138,
          "referenced_widgets": [
            "cf81e5fb9a76441886f26f15e7ecaa8d",
            "2bf9b90ccae944918465312b5c0a6207",
            "95e1fb7a52d14ab59a92bf3624954111",
            "3dabf5b1b7574043b33ca4fbee409762",
            "e36663f8ffc6423097d6914d9a8eadf0",
            "99d7199e1b5344348f52b3cea1b0db02",
            "83a915a450d24571af3b05ead4352215",
            "9386a77c078043b18158da9ff6cbc73b",
            "556646963e384c82a548a2f018292e5f",
            "b08f725a26154cb9b580587caba4d64d",
            "137c5f83d6af450ba9edae9824313caa"
          ]
        },
        "id": "4vTOf7wat5VY",
        "outputId": "4f9a61c4-75a4-4161-ce00-4cefe1e2b870"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columns: ['Unnamed: 0', 'type', 'fact_check_url', 'archieve', 'news_url', 'news_url2', 'news_url3', 'news_url4', 'news_url5', 'title', 'newstitle', 'text', 'abstract', 'publish_date', 'meta_keywords', 'label']\n",
            "Counts -> Fake(0): 125 Real(1): 1397\n",
            "Total rows: 1522\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1522 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cf81e5fb9a76441886f26f15e7ecaa8d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1217  |  Eval: 305\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Use DeBERTa-v3:\n",
        "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "\n",
        "# If you want to keep DistilBERT for speed, uncomment the next line:\n",
        "# MODEL_NAME = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "MAX_LEN = 256\n",
        "def tok(batch):\n",
        "  return tokenizer(batch['text'], padding='max_length', truncation=True, max_length=MAX_LEN)\n",
        "\n",
        "tokenized_train = train_ds.map(tok, batched=True, remove_columns=['text'])\n",
        "tokenized_eval = eval_ds.map(tok, batched=True, remove_columns=['text'])\n",
        "\n",
        "tokenized_train = tokenized_train.with_format(\"torch\")\n",
        "tokenized_eval = tokenized_eval.with_format(\"torch\")\n",
        "\n",
        "print(\"Tokenization complete âœ…\")"
      ],
      "metadata": {
        "id": "xNHLWW71t_Dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer\n",
        "import evaluate\n",
        "\n",
        "# Labels mapping\n",
        "id2label = {0: \"Fake\", 1: \"Real\"}\n",
        "label2id = {\"Fake\": 0, \"Real\": 1}\n",
        "\n",
        "# Load pretrained DeBERTa model\n",
        "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    num_labels=2,\n",
        "    id2label=id2label,\n",
        "    label2id=label2id\n",
        ")\n",
        "\n",
        "# Metrics\n",
        "acc_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    preds = np.argmax(logits, axis=1)\n",
        "    return {\n",
        "        \"accuracy\": acc_metric.compute(predictions=preds, references=labels)['accuracy'],\n",
        "        \"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")['f1'],\n",
        "    }\n",
        "\n",
        "# âœ… TrainingArguments (for old transformers â†’ eval_strategy)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"/content/results\",\n",
        "    eval_strategy=\"steps\",       # âœ… use this instead of evaluation_strategy\n",
        "    save_steps=200,\n",
        "    eval_steps=200,\n",
        "    logging_steps=100,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    greater_is_better=True,\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    weight_decay=0.01,\n",
        "    report_to=\"none\",\n",
        "    seed=42,\n",
        ")\n",
        "\n",
        "# Trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_train,   # <-- make sure you defined these\n",
        "    eval_dataset=tokenized_eval,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# Training\n",
        "train_result = trainer.train()\n",
        "print(\"Training finished âœ…\")\n"
      ],
      "metadata": {
        "id": "MDsvkcMjuBKc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "preds = trainer.predict(tokenized_eval)\n",
        "y_true = preds.label_ids\n",
        "y_pred = np.argmax(preds.predictions, axis=1)\n",
        "print(classification_report(y_true, y_pred, target_names=[\"Fake\",\"Real\"]))"
      ],
      "metadata": {
        "id": "Y9vXx55iuETQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Directory to save model\n",
        "SAVE_DIR = \"/content/final_model\"\n",
        "os.makedirs(SAVE_DIR, exist_ok=True)\n",
        "\n",
        "# Save model and tokenizer\n",
        "trainer.save_model(SAVE_DIR)\n",
        "tokenizer.save_pretrained(SAVE_DIR)\n",
        "\n",
        "# Quick sanity check\n",
        "print(\"Saved files:\", os.listdir(SAVE_DIR))\n",
        "\n",
        "# Check essential files exist\n",
        "assert any(\n",
        "    n.startswith(\"pytorch_model\") or n.endswith(\".safetensors\")\n",
        "    for n in os.listdir(SAVE_DIR)\n",
        "), \"âŒ Model weights missing!\"\n",
        "\n",
        "assert \"config.json\" in os.listdir(SAVE_DIR), \"âŒ config.json missing!\"\n",
        "assert (\n",
        "    \"tokenizer.json\" in os.listdir(SAVE_DIR)\n",
        "    or \"spm.model\" in os.listdir(SAVE_DIR)\n",
        "), \"âŒ Tokenizer files missing!\"\n",
        "\n",
        "print(\"âœ… Model AND tokenizer saved to:\", SAVE_DIR)\n"
      ],
      "metadata": {
        "id": "PGSJNBgSuG69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import wikipedia\n",
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import requests\n",
        "import re\n",
        "\n",
        "# ----------------------------\n",
        "# 1. NewsAPI Key\n",
        "# ----------------------------\n",
        "NEWSAPI_KEY = \"dae9f2abd8434e50b6f277863fd81fe1\"  # replace with your own key\n",
        "\n",
        "# ----------------------------\n",
        "# 2. Load your trained model\n",
        "# ----------------------------\n",
        "SAVE_DIR = \"/content/final_model\"\n",
        "classifier = pipeline(\n",
        "    \"text-classification\",\n",
        "    model=SAVE_DIR,\n",
        "    tokenizer=SAVE_DIR,\n",
        "    return_all_scores=False,\n",
        "    device=-1  # set to 0 if GPU available\n",
        ")\n",
        "\n",
        "# ----------------------------\n",
        "# 3. Sentiment Analyzer\n",
        "# ----------------------------\n",
        "analyzer = SentimentIntensityAnalyzer()\n",
        "\n",
        "# ----------------------------\n",
        "# 4. Helper: Extract keywords\n",
        "# ----------------------------\n",
        "def extract_keywords(text, top_n=3):\n",
        "    words = re.findall(r\"\\w+\", text)\n",
        "    stopwords = {\n",
        "        \"the\", \"is\", \"in\", \"on\", \"of\", \"for\", \"a\", \"an\", \"to\", \"and\",\n",
        "        \"with\", \"show\", \"study\", \"results\"\n",
        "    }\n",
        "    keywords = [w for w in words if w.lower() not in stopwords]\n",
        "    return \" \".join(keywords[:top_n]) if keywords else text\n",
        "\n",
        "# ----------------------------\n",
        "# 5. Wikipedia Snippet\n",
        "# ----------------------------\n",
        "def get_wiki_snippet(q):\n",
        "    try:\n",
        "        try_query = q if len(q.split()) < 6 else \" \".join(q.split()[:6])\n",
        "        return wikipedia.summary(try_query, sentences=3)\n",
        "    except wikipedia.exceptions.DisambiguationError as e:\n",
        "        return f\"Ambiguous term: refine your query. Options: {', '.join(e.options[:5])} ...\"\n",
        "    except Exception:\n",
        "        return \"No relevant Wikipedia page found.\"\n",
        "\n",
        "# ----------------------------\n",
        "# 6. Live News API Fetch\n",
        "# ----------------------------\n",
        "def get_live_api_examples(q):\n",
        "    if not NEWSAPI_KEY:\n",
        "        return \"âš ï¸ Live API not configured.\"\n",
        "    try:\n",
        "        r = requests.get(\n",
        "            \"https://newsapi.org/v2/everything\",\n",
        "            params={\n",
        "                \"q\": q,\n",
        "                \"language\": \"en\",\n",
        "                \"pageSize\": 3,\n",
        "                \"sortBy\": \"publishedAt\",\n",
        "                \"apiKey\": NEWSAPI_KEY\n",
        "            },\n",
        "            timeout=10\n",
        "        )\n",
        "        data = r.json()\n",
        "        if data.get(\"status\") != \"ok\":\n",
        "            return f\"Live API error: {data.get('message','unknown error')}\"\n",
        "        items = []\n",
        "        for art in data.get(\"articles\", []):\n",
        "            items.append(f\"- {art.get('title','(no title)')} ({art.get('source',{}).get('name','')})\")\n",
        "        return \"\\n\".join(items) if items else \"No recent related articles found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Live API request failed: {e}\"\n",
        "\n",
        "# ----------------------------\n",
        "# 7. Main Analyzer Function\n",
        "# ----------------------------\n",
        "def analyze_news(headline):\n",
        "    headline = (headline or \"\").strip()\n",
        "    if not headline:\n",
        "        return \"Please enter a headline.\"\n",
        "\n",
        "    # 1) Fake/Real Prediction\n",
        "    pred = classifier(headline)[0]\n",
        "    label = pred[\"label\"]\n",
        "    conf = float(pred[\"score\"])\n",
        "\n",
        "    # 2) Sentiment\n",
        "    s = analyzer.polarity_scores(headline)\n",
        "    sentiment_label = \"Neutral\"\n",
        "    if s[\"compound\"] >= 0.05:\n",
        "        sentiment_label = \"Positive\"\n",
        "    elif s[\"compound\"] <= -0.05:\n",
        "        sentiment_label = \"Negative\"\n",
        "\n",
        "    # 3) Wikipedia snippet\n",
        "    wiki = get_wiki_snippet(headline)\n",
        "\n",
        "    # 4) Live API (keywords)\n",
        "    search_query = extract_keywords(headline, top_n=3)\n",
        "    live_info = get_live_api_examples(search_query)\n",
        "\n",
        "    # Build Markdown Output\n",
        "    md = []\n",
        "    md.append(\"### ðŸ” Fake News Detection\")\n",
        "    md.append(f\"**Prediction**: **{label}**  |  **Confidence**: {conf:.2f}\")\n",
        "    md.append(\"\")\n",
        "    md.append(\"### ðŸ™‚ Sentiment Analysis\")\n",
        "    md.append(f\"**Sentiment**: **{sentiment_label}**  |  Scores: {s}\")\n",
        "    md.append(\"\")\n",
        "    md.append(\"### ðŸ“– Wikipedia Snippet\")\n",
        "    md.append(wiki)\n",
        "    md.append(\"\")\n",
        "    md.append(f\"### ðŸ“° Live News (Search: `{search_query}`)\")\n",
        "    md.append(live_info)\n",
        "\n",
        "    return \"\\n\".join(md)\n",
        "\n",
        "# ----------------------------\n",
        "# 8. Gradio UI\n",
        "# ----------------------------\n",
        "iface = gr.Interface(\n",
        "    fn=analyze_news,\n",
        "    inputs=gr.Textbox(lines=3, label=\"Enter headline\"),\n",
        "    outputs=gr.Markdown(),\n",
        "    title=\"Real-Time Fake News Detection (DeBERTa-v3)\",\n",
        "    description=\"Classifies news as Fake/Real, gives sentiment, shows Wikipedia snippet, and fetches related live news.\"\n",
        ")\n",
        "\n",
        "iface.launch(share=True, debug=True)\n"
      ],
      "metadata": {
        "id": "wEbc8EaWuKt8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-M9AobLBuPyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P0888Fz0c3mY"
      },
      "source": [
        "import numpy as np\n",
        "from transformers import (AutoModelForSequenceClassification, TrainingArguments, Trainer)\n",
        "import evaluate\n",
        "\n",
        "id2label = {0: \"Fake\", 1: \"Real\"}\n",
        "label2id = {\"Fake\": 0, \"Real\": 1}\n",
        "\n",
        "MODEL_NAME = \"microsoft/deberta-v3-base\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME,num_labels=2,id2label=id2label,label2id=label2id)\n",
        "\n",
        "# Metrics\n",
        "acc_metric = evaluate.load(\"accuracy\")\n",
        "f1_metric = evaluate.load(\"f1\")\n",
        "def compute_metrics(eval_pred):\n",
        "  logits, labels = eval_pred\n",
        "  preds = np.argmax(logits, axis=1)\n",
        "  return {\"accuracy\": acc_metric.compute(predictions=preds, references=labels)['accuracy'],\n",
        "\"f1\": f1_metric.compute(predictions=preds, references=labels, average=\"macro\")['f1'],}\n",
        "\n",
        "# âœ… Put TrainingArguments here (bef ore Trainer)\n",
        "training_args = TrainingArguments(output_dir=\"/content/results\",\n",
        "                                  evaluation_strategy=\"steps\", # Corrected parameter name\n",
        "                                  save_steps=200,\n",
        "                                  eval_steps=200,\n",
        "                                  logging_steps=100,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  metric_for_best_model=\"f1\",\n",
        "                                  greater_is_better=True,\n",
        "                                  num_train_epochs=3,\n",
        "                                  per_device_train_batch_size=8,\n",
        "                                  per_device_eval_batch_size=8,\n",
        "                                  weight_decay=0.01,\n",
        "                                  report_to=\"none\",\n",
        "                                  seed=42,)\n",
        "# Trainer\n",
        "trainer = Trainer(model=model,args=training_args,train_dataset=tokenized_train,eval_dataset=tokenized_eval,tokenizer=tokenizer,compute_metrics=compute_metrics)\n",
        "# Training\n",
        "train_result = trainer.train()\n",
        "print(\"Training finished âœ…\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}